{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "15d9d2e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7848066d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Motion Data\n",
    "user_1001_1 = pd.read_csv(r\"C:\\Users\\roger\\Desktop\\New Complete\\3022\\20191208152726_20191209222327_ACC.csv\",  encoding='utf-8')\n",
    "user_1001_2 = pd.read_csv(r\"C:\\Users\\roger\\Desktop\\New Complete\\3022\\20191209222833_20191210224854_ACC.csv\",  encoding='utf-8')\n",
    "user_1001_3 = pd.read_csv(r\"C:\\Users\\roger\\Desktop\\New Complete\\3022\\20191210225345_20191211230723_ACC.csv\",  encoding='utf-8')\n",
    "user_1001_4 = pd.read_csv(r\"C:\\Users\\roger\\Desktop\\New Complete\\3022\\20191211231313_20191212215646_ACC.csv\",  encoding='utf-8')\n",
    "user_1001_5 = pd.read_csv(r\"C:\\Users\\roger\\Desktop\\New Complete\\3022\\20191212220704_20191213225926_ACC.csv\",  encoding='utf-8')\n",
    "user_1001 = pd.concat([user_1001_1, user_1001_2, user_1001_3, user_1001_4, user_1001_5], axis = 0)\n",
    "user_1001['csv_time_motion'] = user_1001['csv_time_motion'].astype(str).str.strip()\n",
    "user_1001['csv_time'] = pd.to_datetime(user_1001['csv_time_motion'], errors = 'coerce')\n",
    "mask = user_1001['csv_time'].isna()\n",
    "user_1001.loc[mask, 'csv_motion'] = pd.to_datetime(user_1001.loc[mask, 'csv_time_motion'], format = \"%d-%b-%Y %H:%M:%S\")\n",
    "user_1001['cleaned_stamp'] = user_1001['csv_time'].combine_first(user_1001['csv_motion'])\n",
    "user_1001.drop(columns = ['csv_time_motion', 'csv_time', 'csv_motion'], inplace = True)\n",
    "user_1001 = user_1001.groupby(['cleaned_stamp'])[['Motion_dataX', 'Motion_dataY', 'Motion_dataZ']].mean().reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1239ac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PPG Data\n",
    "user_ppg1 = pd.read_csv(r\"C:\\Users\\roger\\Desktop\\New Complete\\3022\\20191208152726_20191209222327_PPG.csv\")\n",
    "user_ppg2 = pd.read_csv(r\"C:\\Users\\roger\\Desktop\\New Complete\\3022\\20191209222833_20191210224854_PPG.csv\")\n",
    "user_ppg3 = pd.read_csv(r\"C:\\Users\\roger\\Desktop\\New Complete\\3022\\20191210225345_20191211230723_PPG.csv\")\n",
    "user_ppg4 = pd.read_csv(r\"C:\\Users\\roger\\Desktop\\New Complete\\3022\\20191211231313_20191212215646_PPG.csv\")\n",
    "user_ppg5 = pd.read_csv(r\"C:\\Users\\roger\\Desktop\\New Complete\\3022\\20191212220704_20191213225926_PPG.csv\")\n",
    "\n",
    "user_ppg = pd.concat([user_ppg1, user_ppg2, user_ppg3, user_ppg4, user_ppg5], axis = 0)\n",
    "user_ppg = user_ppg.reset_index(drop = True)\n",
    "user_ppg['csv_time_PPG'] = user_ppg['csv_time_PPG'].astype(str).str.strip()\n",
    "user_ppg['csv_ppg'] = pd.to_datetime(user_ppg['csv_time_PPG'], format = \"%d-%b-%Y %H:%M:%S\", errors = 'coerce')\n",
    "mask = user_ppg['csv_ppg'].isna()\n",
    "user_ppg.loc[mask, 'csv_time'] = pd.to_datetime(user_ppg['csv_time_PPG'], errors = 'coerce')\n",
    "user_ppg['cleaned_st'] = user_ppg['csv_time'].combine_first(user_ppg['csv_ppg'])\n",
    "user_ppg.drop(columns = ['csv_time_PPG', 'csv_time', 'csv_ppg'], inplace = True)\n",
    "user_ppg = user_ppg.groupby(['cleaned_st'])[['PPG']].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a4489ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GSR Data\n",
    "user_gsr1 = pd.read_csv(r\"C:\\Users\\roger\\Desktop\\New Complete\\3022\\20191208152726_20191209222327_GSR.csv\")\n",
    "user_gsr2 = pd.read_csv(r\"C:\\Users\\roger\\Desktop\\New Complete\\3022\\20191209222833_20191210224854_GSR.csv\")\n",
    "user_gsr3 = pd.read_csv(r\"C:\\Users\\roger\\Desktop\\New Complete\\3022\\20191210225345_20191211230723_GSR.csv\")\n",
    "user_gsr4 = pd.read_csv(r\"C:\\Users\\roger\\Desktop\\New Complete\\3022\\20191211231313_20191212215646_GSR.csv\")\n",
    "user_gsr5 = pd.read_csv(r\"C:\\Users\\roger\\Desktop\\New Complete\\3022\\20191212220704_20191213225926_GSR.csv\")\n",
    "user_gsr = pd.concat([user_gsr1, user_gsr2, user_gsr3, user_gsr4, user_gsr5], axis = 0)\n",
    "user_gsr.head()\n",
    "user_gsr = user_gsr.reset_index(drop = True)\n",
    "user_gsr['csv_time_GSR'] = user_gsr['csv_time_GSR'].astype(str).str.strip()\n",
    "user_gsr['csv_time'] = pd.to_datetime(user_gsr['csv_time_GSR'], errors = 'coerce')\n",
    "mask = user_gsr['csv_time'].isna()\n",
    "user_gsr.loc[mask, 'time_gsr'] = pd.to_datetime(user_gsr['csv_time_GSR'], format = \"%d-%b-%Y %H:%M:%S\", errors = 'coerce')\n",
    "user_gsr['cleaned_time'] = user_gsr['csv_time'].combine_first(user_gsr['time_gsr'])\n",
    "user_gsr.drop(columns = ['csv_time_GSR', 'csv_time', 'time_gsr'], inplace = True)\n",
    "user_gsr = user_gsr.groupby(['cleaned_time'])[['GSR']].mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8458359",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# Heart Rate Data\n",
    "user_hr1 = pd.read_csv(r\"C:\\Users\\roger\\Desktop\\New Complete\\3022\\20191208152726_20191209222327.csv\")\n",
    "user_hr2 = pd.read_csv(r\"C:\\Users\\roger\\Desktop\\New Complete\\3022\\20191209222833_20191210224854.csv\")\n",
    "user_hr3 = pd.read_csv(r\"C:\\Users\\roger\\Desktop\\New Complete\\3022\\20191210225345_20191211230723.csv\")\n",
    "user_hr4 = pd.read_csv(r\"C:\\Users\\roger\\Desktop\\New Complete\\3022\\20191211231313_20191212215646.csv\")\n",
    "user_hr5 = pd.read_csv(r\"C:\\Users\\roger\\Desktop\\New Complete\\3022\\20191212220704_20191213225926.csv\")\n",
    "user_hr = pd.concat([user_hr1, user_hr2, user_hr3, user_hr4, user_hr5], axis = 0)\n",
    "user_hr = user_hr.reset_index(drop = True)\n",
    "user_hr['time'] = user_hr['time'].astype(str).str.strip()\n",
    "user_hr['timestamp'] = pd.to_datetime(user_hr['time'], errors = 'coerce')\n",
    "mask = user_hr['timestamp'].isna()\n",
    "np.sum(user_hr['timestamp'].isna())\n",
    "empty = user_hr[user_hr['timestamp'].isna()]\n",
    "for i, row in empty.iterrows():\n",
    "    user_hr.iloc[i, 5] = row['time'].replace(\"/\", \"-\") + \" 00:00:00\"\n",
    "user_hr['timestamp'] = pd.to_datetime(user_hr['timestamp'], errors = 'coerce')\n",
    "user_hr.drop(columns = ['motion', 'GSR', 'battery_info', 'time'], inplace = True)\n",
    "user_hr = user_hr.groupby(['timestamp'])[['heart_rate']].mean().reset_index()\n",
    "dataset = pd.concat([user_hr.reset_index(drop = True), user_1001.reset_index(drop = True), user_gsr.reset_index(drop = True), user_ppg.reset_index(drop = True)], axis = 1)\n",
    "\n",
    "\n",
    "i = 0\n",
    "for _, rows in dataset.iterrows():\n",
    "    if not (rows['timestamp'] == rows['cleaned_stamp'] == rows['cleaned_time'] == rows['cleaned_st']):\n",
    "        i+=1\n",
    "print(i)\n",
    "dataset.drop(columns = ['cleaned_stamp', 'cleaned_time', 'cleaned_st'], inplace = True)\n",
    "dataset.rename(columns = {'timestamp' : 'Timestamp'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b426ca30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering\n",
    "dataset['Timestamp'] = dataset['Timestamp'].astype(str).str.strip()\n",
    "dataset['Timestamp'] = pd.to_datetime(dataset['Timestamp'], errors = 'coerce')\n",
    "dataset['Hour'] = dataset['Timestamp'].dt.hour\n",
    "dataset['Minute'] = dataset['Timestamp'].dt.minute\n",
    "dataset['Weekday'] = dataset['Timestamp'].dt.weekday\n",
    "dataset['is_weekend'] = dataset['Weekday'].apply(lambda x : 1 if x >=5 else 0)\n",
    "dataset['Movement'] = np.sqrt(dataset['Motion_dataX']**2 + dataset['Motion_dataY']**2 + dataset['Motion_dataZ']**2)\n",
    "dataset['Roll_mov_avg'] = dataset['Movement'].rolling(window = 60).mean()\n",
    "dataset['Roll_mov_std'] = dataset['Movement'].rolling(window = 60).std()\n",
    "dataset['Roll_ppg_avg'] = dataset['PPG'].rolling(window = 60).mean()\n",
    "dataset['Roll_ppg_std'] = dataset['PPG'].rolling(window = 60).std()\n",
    "dataset['Roll_ppg_min'] = dataset['PPG'].rolling(window = 60).min()\n",
    "dataset['Roll_ppg_max'] = dataset['PPG'].rolling(window = 60).max()\n",
    "dataset['Roll_hr_avg'] = dataset['heart_rate'].rolling(window = 60).mean()\n",
    "dataset['Roll_hr_std'] = dataset['heart_rate'].rolling(window = 60).std()\n",
    "dataset['hr_x_gsr'] = dataset['heart_rate']*dataset['GSR']\n",
    "dataset['hr_x_Movement'] = dataset['heart_rate']* dataset['Movement']\n",
    "dataset['ppg_x_gsr'] = dataset['PPG']*dataset['GSR']\n",
    "dataset['hr_diff'] = dataset['heart_rate'].diff()\n",
    "dataset = dataset.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "95292262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mood Data Integration\n",
    "drm_1001 = pd.read_excel(r\"C:\\Users\\roger\\Desktop\\New Complete\\DRM.xlsx\")\n",
    "drm_1001.drop(columns = ['Event ID', 'Time to complete (milliseconds)'], inplace = True)\n",
    "drm_1001 = drm_1001[drm_1001['Participant ID'] == 3022]\n",
    "drm_1001.rename(columns = {'PANAS_1' : 'upset', 'PANAS_2' : 'hostile', 'PANAS_3' : 'alert', 'PANAS_4' : 'ashamed', \n",
    "                           'PANAS_5' : 'inspired', 'PANAS_6' : 'nervous', 'PANAS_7' : 'determined', 'PANAS_8' : 'attentive',\n",
    "                           'PANAS_9' : 'afraid', 'PANAS_10' : 'active', 'Valence' : 'valence', 'Arousal' : 'arousal'}, inplace = True)\n",
    "drm_1001[['start time', 'end time']] = drm_1001['start | end time'].str.split(\"|\", expand = True)\n",
    "drm_1001['Submission time'] = pd.to_datetime(drm_1001['Submission time'], errors = 'coerce')\n",
    "drm_1001['Submission date'] = drm_1001['Submission time'].dt.date\n",
    "drm_1001['start'] = pd.to_datetime(drm_1001['Submission date'].astype(str) + \" \" + drm_1001['start time'], errors = 'coerce')\n",
    "drm_1001['end'] = pd.to_datetime(drm_1001['Submission date'].astype(str) + \" \" + drm_1001['end time'], errors = 'coerce')\n",
    "drm_1001.drop(columns = ['Submission time', 'start | end time', 'start time','end time', 'Submission date'], inplace = True)\n",
    "drm_1001.rename(columns = {'start' : 'start time', 'end' : 'end time'}, inplace = True)\n",
    "drm_1001['start time'] = pd.to_datetime(drm_1001['start time'], errors = 'coerce')\n",
    "drm_1001['end time'] = pd.to_datetime(drm_1001['end time'], errors = 'coerce')\n",
    "drm_1001 = drm_1001.drop_duplicates()\n",
    "\n",
    "\n",
    "\n",
    "emotions = pd.DataFrame()\n",
    "start_idx = 0\n",
    "for _, row in drm_1001.iterrows():\n",
    "    start_time = row['start time']\n",
    "    end_time= row['end time']\n",
    "    for i in range(start_idx, len(dataset)):\n",
    "        anrow = dataset.iloc[i]\n",
    "        timestamp = anrow['Timestamp']\n",
    "        if start_time <= timestamp <= end_time:\n",
    "            moods = pd.DataFrame([row[:13].to_dict()])\n",
    "            emotions = pd.concat([emotions, moods], axis = 0)\n",
    "        elif timestamp > end_time:\n",
    "            start_idx = i\n",
    "            break\n",
    "\n",
    "df = pd.DataFrame()\n",
    "start_idx1 = 0\n",
    "for i in range(len(drm_1001)):\n",
    "    row = drm_1001.iloc[i]\n",
    "    start_time = row['start time']\n",
    "    end_time = row['end time']\n",
    "    for i in range(start_idx1, len(dataset)):\n",
    "        anrow = dataset.iloc[i]\n",
    "        timestamp = anrow['Timestamp']\n",
    "        if start_time <= timestamp <= end_time:\n",
    "            df = pd.DataFrame([anrow[:].to_dict()])\n",
    "            data = pd.concat([dataset, df], axis = 0)\n",
    "        elif timestamp > end_time:\n",
    "            start_idx1 = i\n",
    "            break\n",
    "\n",
    "dataset = pd.concat([dataset.reset_index(drop = True), emotions.reset_index(drop = True)], axis = 1)\n",
    "emotion_columns = ['upset', 'hostile', 'alert', 'ashamed', 'inspired', 'nervous', \n",
    "                   'determined', 'attentive', 'afraid', 'active', 'valence', 'arousal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "75df2e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Timestamp', 'heart_rate', 'Motion_dataX', 'Motion_dataY',\n",
       "       'Motion_dataZ', 'GSR', 'PPG', 'Hour', 'Minute', 'Weekday', 'is_weekend',\n",
       "       'Movement', 'Roll_mov_avg', 'Roll_mov_std', 'Roll_ppg_avg',\n",
       "       'Roll_ppg_std', 'Roll_ppg_min', 'Roll_ppg_max', 'Roll_hr_avg',\n",
       "       'Roll_hr_std', 'hr_x_gsr', 'hr_x_Movement', 'ppg_x_gsr', 'hr_diff',\n",
       "       'Participant ID', 'upset', 'hostile', 'alert', 'ashamed', 'inspired',\n",
       "       'nervous', 'determined', 'attentive', 'afraid', 'active', 'valence',\n",
       "       'arousal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "01f525ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[emotion_columns] = dataset[emotion_columns].applymap(lambda x : 1 if x >= 3 else 0)\n",
    "dataset[\"mood\"] = np.NaN\n",
    "angry_mask = (dataset['hostile'] == 1) & (dataset['mood'].isna())\n",
    "dataset.loc[angry_mask, \"mood\"] = \"angry\"\n",
    "\n",
    "happy_mask = ((dataset['active'] == 1) & (dataset['attentive'] == 1) & (dataset['determined'] == 1)\n",
    "           & (dataset['inspired'] == 1) & dataset['mood'].isna()) | ((dataset['active'] == 1) & (dataset['determined'] == 1)\n",
    "                                         & (dataset['inspired'] == 1) & dataset['mood'].isna()) | ((dataset['inspired'] == 1) & \n",
    "                                                                      (dataset['active'] == 1) & dataset['mood'].isna()) | ((dataset['determined'] == 1) & \n",
    "                                                                                               (dataset['active'] == 1) & dataset['mood'].isna()) | ((dataset['inspired'] == 1) & dataset['mood'].isna())\n",
    "dataset.loc[happy_mask, \"mood\"] = \"happy\"\n",
    "\n",
    "sad_mask =  ((dataset['upset'] == 1) & (dataset['ashamed'] == 1) & (dataset['nervous'] == 1) & \n",
    "             dataset['mood'].isna()) | ((dataset['upset'] == 1) & (dataset['ashamed'] == 1) & \n",
    "                                     dataset['mood'].isna()) | ((dataset['upset'] == 1) & \n",
    "                                                             dataset['mood'].isna()) | ((dataset['ashamed'] == 1) & dataset['mood'].isna())\n",
    "dataset.loc[sad_mask, \"mood\"] = \"sad\"\n",
    "\n",
    "neutral_mask = dataset['mood'].isna()\n",
    "dataset.loc[neutral_mask, \"mood\"] = \"neutral\"\n",
    "dataset = dataset.drop(columns = ['Participant ID', 'upset', 'hostile', 'alert', 'ashamed', 'inspired',\n",
    "       'nervous', 'determined', 'attentive', 'afraid', 'active', 'valence',\n",
    "       'arousal'])\n",
    "\n",
    "dataset['sin_hour'] = np.sin(2*np.pi*dataset['Hour']/24)\n",
    "dataset['cos_hour'] = np.cos(2*np.pi*dataset['Hour']/24)\n",
    "dataset['sin_minute'] = np.sin(2*np.pi*dataset['Minute']/60)\n",
    "dataset['cos_minute'] = np.cos(2*np.pi*dataset['Minute']/60)\n",
    "dataset['sin_weekday'] = np.sin(2*np.pi*dataset['Weekday']/7)\n",
    "dataset['cos_weekday'] = np.cos(2*np.pi*dataset['Weekday']/7)\n",
    "\n",
    "dataset.drop(columns = ['Timestamp', 'Hour', 'Minute', 'Weekday'], inplace = True)\n",
    "\n",
    "mood_map = {\"happy\" : 0,\n",
    "            \"sad\" : 1,\n",
    "            \"angry\" : 2,\n",
    "            \"neutral\" : 3}\n",
    "dataset['true_label'] = dataset['mood'].map(mood_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "976d7f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "dataset[['heart_rate', 'Motion_dataX', 'Motion_dataY', 'Motion_dataZ', 'GSR',\n",
    "       'PPG', 'is_weekend', 'Movement', 'Roll_mov_avg', 'Roll_mov_std',\n",
    "       'Roll_ppg_avg', 'Roll_ppg_std', 'Roll_ppg_min', 'Roll_ppg_max',\n",
    "       'Roll_hr_avg', 'Roll_hr_std', 'hr_x_gsr', 'hr_x_Movement', 'ppg_x_gsr',\n",
    "       'hr_diff', 'sin_hour', 'cos_hour', 'sin_minute', 'cos_minute',\n",
    "       'sin_weekday', 'cos_weekday']] = scaler.fit_transform(dataset[['heart_rate', 'Motion_dataX', 'Motion_dataY', 'Motion_dataZ', 'GSR',\n",
    "       'PPG', 'is_weekend', 'Movement', 'Roll_mov_avg', 'Roll_mov_std',\n",
    "       'Roll_ppg_avg', 'Roll_ppg_std', 'Roll_ppg_min', 'Roll_ppg_max',\n",
    "       'Roll_hr_avg', 'Roll_hr_std', 'hr_x_gsr', 'hr_x_Movement', 'ppg_x_gsr',\n",
    "       'hr_diff', 'sin_hour', 'cos_hour', 'sin_minute', 'cos_minute',\n",
    "       'sin_weekday', 'cos_weekday']])\n",
    "\n",
    "#sam_df = dataset.sample(n = 600, replace = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c862602e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true_label\n",
       "3    361811\n",
       "0     39486\n",
       "1      8702\n",
       "2      7503\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['true_label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ab38e3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_df = dataset[dataset['true_label'] == 2]\n",
    "sam_df = dataset.sample(n = 600, replace = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "769daab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_df.to_csv(r\"C:\\Users\\roger\\Desktop\\New Complete\\mood_sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040d29e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
